{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FTTransformer_and_co.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2RX38Hg7sYf"
      },
      "outputs": [],
      "source": [
        "! pip install pytorch_tabular[all]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch_tabular\n"
      ],
      "metadata": {
        "id": "YFt3pYG9CBRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/manujosephv/pytorch_tabular\n"
      ],
      "metadata": {
        "id": "skm4M3kNCDA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pytorch_tabular\n"
      ],
      "metadata": {
        "id": "mWebg7kxCESQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n"
      ],
      "metadata": {
        "id": "DU38YNFNCFX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install\n"
      ],
      "metadata": {
        "id": "tt8KCSJHCH8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==59.5.0\n"
      ],
      "metadata": {
        "id": "O4SYdQ0qCJ5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "pLkTlOzNCK5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "if not IN_COLAB:\n",
        "    os.chdir(\"..\")\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pytorch_tabular import TabularModel\n",
        "from pytorch_tabular.models import CategoryEmbeddingModelConfig, FTTransformerConfig, FTTransformerModel, TabNetModelConfig, TabNetModel, AutoIntConfig, AutoIntConfig, TabTransformerConfig, TabTransformerModel\n",
        "from pytorch_tabular.models import AutoIntModel, AutoIntConfig, NodeConfig, NODEModel\n",
        "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig, ModelConfig\n",
        "from pytorch_tabular.models import BaseModel\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from omegaconf import DictConfig\n",
        "from typing import Dict\n",
        "from dataclasses import dataclass, field\n"
      ],
      "metadata": {
        "id": "5qmuotr7_UO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mixed_regression(n_samples, n_features, n_categories):\n",
        "    X,y = make_regression(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5, n_targets=1)\n",
        "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\n",
        "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\n",
        "    for col in cat_cols:\n",
        "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\n",
        "    col_names = [] \n",
        "    num_col_names=[]\n",
        "    cat_col_names=[]\n",
        "    for i in range(X.shape[-1]):\n",
        "        if i in cat_cols:\n",
        "            col_names.append(f\"cat_col_{i}\")\n",
        "            cat_col_names.append(f\"cat_col_{i}\")\n",
        "        if i in num_cols:\n",
        "            col_names.append(f\"num_col_{i}\")\n",
        "            num_col_names.append(f\"num_col_{i}\")\n",
        "    X = pd.DataFrame(X, columns=col_names)\n",
        "    y = pd.DataFrame(y, columns=[\"target\"])\n",
        "    data = X.join(y)\n",
        "    return data, cat_col_names, num_col_names\n",
        "\n",
        "def print_metrics(y_true, y_pred, tag):\n",
        "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
        "        y_true = y_true.values\n",
        "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
        "        y_pred = y_pred.values\n",
        "    if y_true.ndim>1:\n",
        "        y_true=y_true.ravel()\n",
        "    if y_pred.ndim>1:\n",
        "        y_pred=y_pred.ravel()\n",
        "    val_acc = mean_squared_error(y_true, y_pred)\n",
        "    val_f1 = mean_absolute_error(y_true, y_pred)\n",
        "    print(f\"{tag} MSE: {val_acc} | {tag} MAE: {val_f1}\")\n",
        "\n",
        "data, cat_col_names, num_col_names = make_mixed_regression(n_samples=10000, n_features=4, n_categories=2)\n",
        "df_train, df_test = train_test_split(data, random_state=42)\n",
        "df_train, df_valid = train_test_split(data, random_state=42)"
      ],
      "metadata": {
        "id": "fshllPcm_Znv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FT - Transformer\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=['num_col_0', 'num_col_3'],\n",
        "    categorical_cols=['cat_col_1', 'cat_col_2'],\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = FTTransformerConfig(\n",
        "    task = \"regression\",\n",
        "    learning_rate=1e-3,\n",
        "    seed = 13,\n",
        "    input_embed_dim = 32,\n",
        "    num_heads = 8,\n",
        "    num_attn_blocks = 6,\n",
        "    ff_dropout = 0.1,\n",
        "    out_ff_layers = \"128-64-32\",\n",
        "    out_ff_activation = \"LeakyReLU\",\n",
        "    out_ff_initialization=\"kaiming\",\n",
        "    batch_norm_continuous_input=False,\n",
        "    #         target_range=[(df_train[col].min(),df_train[col].max()) for col in ['target']]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")"
      ],
      "metadata": {
        "id": "3IR36FyA8s6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabular_model.fit(train=df_train, validation=df_valid)"
      ],
      "metadata": {
        "id": "t75kvmAy-_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction and visualization"
      ],
      "metadata": {
        "id": "9ImtR_xUJ2KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, quantiles=[0.15,0.5,0.85], n_samples=1000, ret_logits=False)\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "xjbtykP_AQ03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, quantiles=[0.15,0.5,0.85], n_samples=1000, ret_logits=False)\n",
        "pred_df.head()\n",
        "\n",
        "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
      ],
      "metadata": {
        "id": "rG8jEEyRNUOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_df['num_col_0'], pred_df['target'], color = 'blue')\n",
        "plt.scatter(pred_df['num_col_0'], pred_df['target_prediction'], color = 'red')"
      ],
      "metadata": {
        "id": "-pNNU1iKNfbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_df['num_col_3'], pred_df['target'], color = 'blue')\n",
        "plt.scatter(pred_df['num_col_3'], pred_df['target_prediction'], color = 'red')"
      ],
      "metadata": {
        "id": "rdtgYVPONgk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_df['cat_col_1'], pred_df['target'], color = 'blue')\n",
        "plt.scatter(pred_df['cat_col_1'], pred_df['target_prediction'], color = 'red')"
      ],
      "metadata": {
        "id": "GWimhnBZORos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_df['cat_col_2'], pred_df['target'], color = 'blue')\n",
        "plt.scatter(pred_df['cat_col_2'], pred_df['target_prediction'], color = 'red')"
      ],
      "metadata": {
        "id": "lnnY6dPJOSik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode"
      ],
      "metadata": {
        "id": "vKPFshoXKKQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TabNet\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=['num_col_2', 'num_col_3'],\n",
        "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = TabNetModelConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model.fit(train=df_train, validation=df_valid)"
      ],
      "metadata": {
        "id": "PWquNQZyoXc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
        "pred_df.head()\n",
        "\n",
        "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
      ],
      "metadata": {
        "id": "L1JesRev2pE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Node\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=['num_col_2', 'num_col_3'],\n",
        "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = NodeConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model.fit(train=df_train, validation=df_valid)"
      ],
      "metadata": {
        "id": "ELS4GLsaoXhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
        "pred_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "TQQblmaFoXld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
      ],
      "metadata": {
        "id": "YnbHb-WkoXnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TabTransformer\n",
        "\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=['num_col_2', 'num_col_3'],\n",
        "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = TabTransformerConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model.fit(train=df_train, validation=df_valid)\n",
        "\n"
      ],
      "metadata": {
        "id": "B10Y-fMGoXpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
        "pred_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "ysOlamLKoXrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
      ],
      "metadata": {
        "id": "-hmyBB-NoXtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoInt\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=['num_col_2', 'num_col_3'],\n",
        "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = AutoIntConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model.fit(train=df_train, validation=df_valid)\n",
        "\n"
      ],
      "metadata": {
        "id": "_NehzRQkoXvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
        "pred_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "x9Vxp2Mc3-Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
      ],
      "metadata": {
        "id": "mK6pM2CL3-W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0VmRC27B3-ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NZigDn_f3-bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6-gaG2vQ3-d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v_Y_EHYw3-fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rwRefHkIoXyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J-iNv_AIYq6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "amR7Rg5fYq84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2oNVHe_gYrBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ATxm5bn3YrDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uncertainity_estimate(x, model, num_samples, l2):\n",
        "    outputs = np.hstack([model(x).cpu().detach().numpy() for i in range(num_samples)]) # n번 inference, output.shape = [20, N]\n",
        "    y_mean = outputs.mean(axis=1)\n",
        "    y_variance = outputs.var(axis=1)\n",
        "    tau = l2 * (1. - model.dropout_rate) / (2. * N * model.decay)\n",
        "    y_variance += (1. / tau)\n",
        "    y_std = np.sqrt(y_variance)\n",
        "    return y_mean, y_std"
      ],
      "metadata": {
        "id": "S5uhqywhYrFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}