{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies and libraries"
      ],
      "metadata": {
        "id": "9NqfvaUqCmel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2RX38Hg7sYf"
      },
      "outputs": [],
      "source": [
        "! pip install pytorch_tabular\n",
        "! git clone https://github.com/manujosephv/pytorch_tabular\n",
        "%cd pytorch_tabular\n",
        "\n",
        "!python setup.py install\n",
        "!pip install setuptools==59.5.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qmuotr7_UO0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "if not IN_COLAB:\n",
        "    os.chdir(\"..\")\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pytorch_tabular import TabularModel\n",
        "from pytorch_tabular.models import CategoryEmbeddingModelConfig, FTTransformerConfig, FTTransformerModel, TabNetModelConfig, TabNetModel, AutoIntConfig, AutoIntConfig, TabTransformerConfig, TabTransformerModel\n",
        "from pytorch_tabular.models import AutoIntModel, AutoIntConfig, NodeConfig, NODEModel\n",
        "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig, ModelConfig\n",
        "from pytorch_tabular.models import BaseModel\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from omegaconf import DictConfig\n",
        "from typing import Dict\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for plots\n",
        "font = {'family': 'serif',\n",
        "        'color':  'darkred',\n",
        "        'weight': 'normal',\n",
        "        'size': 16\n",
        "        }\n",
        "\n",
        "font_title = {'family': 'serif',\n",
        "        'color':  'darkred',\n",
        "        'weight': 'normal',\n",
        "        'size': 20\n",
        "        }\n",
        "\n",
        "# Set random seed\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FT-Transformer architecture"
      ],
      "metadata": {
        "id": "OlVcukXkKWPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.linspace(0,100, 10000), np.sin(0.1*np.linspace(0,100, 10000)) + 0.03*np.linspace(0,100, 10000))"
      ],
      "metadata": {
        "id": "8_xXNX08KTFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(np.linspace(0,100, 10000), np.sin(0.1*np.linspace(0,100, 10000)) + 0.03*np.linspace(0,100, 10000), random_state = 42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val)\n",
        "\n",
        "df_train = pd.DataFrame({'col1':X_train, 'cat1':0, 'target':y_train})\n",
        "df_valid = pd.DataFrame({'col1':X_val, 'cat1':0, 'target':y_val})\n",
        "df_test = pd.DataFrame({'col1':X_test, 'cat1':0, 'target':y_test})"
      ],
      "metadata": {
        "id": "Nl8I5yzfKTR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FT - Transformer (new data)\n",
        "num_col_names = ['col1']\n",
        "cat_col_names = ['cat1']\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 1000\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=num_col_names,\n",
        "    categorical_cols=cat_col_names,\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 10,\n",
        "    gpus=None,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":10})\n",
        "\n",
        "\n",
        "model_config = FTTransformerConfig(\n",
        "    task = \"regression\",\n",
        "    learning_rate=1e-4,\n",
        "    seed = 42,\n",
        "    input_embed_dim = 32,\n",
        "    num_heads = 16,\n",
        "    num_attn_blocks = 10,\n",
        "    ff_dropout = 0.2,\n",
        "    out_ff_layers = \"1024-512-256\",\n",
        "    #out_ff_activation = \"LeakyReLU\",\n",
        "    out_ff_activation = \"ReLU\",\n",
        "    out_ff_initialization=\"kaiming\",\n",
        "    batch_norm_continuous_input=False,\n",
        "    #         target_range=[(df_train[col].min(),df_train[col].max()) for col in ['target']]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")"
      ],
      "metadata": {
        "id": "VJQQU446KTYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabular_model.fit(train = df_train, validation=df_valid)"
      ],
      "metadata": {
        "id": "z2SRU9AlKTav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = tabular_model.predict(df_test, ret_logits=False)\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "m1cdCrNJKTck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outputs = np.vstack([tabular_model.predict(df_test, ret_logits=False)['target_prediction'] for i in range(5)])\n",
        "result = tabular_model.predict(df_test, )\n",
        "result"
      ],
      "metadata": {
        "id": "IbzNQSD0IaN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CB1saw_hIaUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = FTTransformerConfig(\n",
        "    task = \"regression\",\n",
        "    learning_rate=1e-4,\n",
        "    seed = 42,\n",
        "    input_embed_dim = 32,\n",
        "    num_heads = 16,\n",
        "    num_attn_blocks = 10,\n",
        "    ff_dropout = 0.2,\n",
        "    out_ff_layers = \"1024-512-256\",\n",
        "    out_ff_activation = \"LeakyReLU\",\n",
        "    #out_ff_activation = \"ReLU\",\n",
        "    out_ff_initialization=\"kaiming\",\n",
        "    batch_norm_continuous_input=False,\n",
        "    #         target_range=[(df_train[col].min(),df_train[col].max()) for col in ['target']]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model_leakeyrelu = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model_leakeyrelu.fit(train=df_train, validation=df_valid)\n",
        "\n",
        "pred_df_leakeyrelu = tabular_model_leakeyrelu.predict(df_test, ret_logits=False)\n",
        "pred_df_leakeyrelu.head()"
      ],
      "metadata": {
        "id": "LtGPsXr1QaZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "--EDcUzjQabu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z95DKoafQad0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RW9e4MPtQagP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eyx82LUQQah9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize = (15,12))\n",
        "plt.scatter(pred_df['col1'], pred_df['target_prediction'], label = 'FT-Transform prediction (with ReLU activation)')\n",
        "plt.scatter(pred_df_leakeyrelu['col1'], pred_df_leakeyrelu['target_prediction'], label = 'FT-Transform prediction (with LeakeyRelu activation)')\n",
        "plt.scatter(pred_df['col1'], pred_df['target'], label = 'True')\n",
        "plt.xlabel(\"X\", fontdict = font)\n",
        "plt.ylabel(\"Y = sin(0.1X) + 0.03X\", fontdict = font)\n",
        "plt.title(\"Homoskedastic and continuous dataset\", fontdict = font_title)\n",
        "plt.legend(fontsize = 14);"
      ],
      "metadata": {
        "id": "i_F8OlpGKTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jWAcSy2JKThR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2fARR9_uKTji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ceL69fp3KTle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1isESJyYKTns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dsKZayO5KTpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet"
      ],
      "metadata": {
        "id": "99ugYYZr2QPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWquNQZyoXc4"
      },
      "outputs": [],
      "source": [
        "# TabNet\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=num_col_names,\n",
        "    categorical_cols=cat_col_names,\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=None,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = TabNetModelConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model_tabnet = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model_tabnet.fit(train=df_train, validation=df_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1JesRev2pE0"
      },
      "outputs": [],
      "source": [
        "pred_df_tabnet = tabular_model_tabnet.predict(df_test, ret_logits=False)\n",
        "pred_df_tabnet.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,12))\n",
        "plt.scatter(pred_df['col1'], pred_df['target_prediction'], label = 'FT-Transform prediction (with ReLU activation)', color = 'purple')\n",
        "plt.scatter(pred_df_leakeyrelu['col1'], pred_df_leakeyrelu['target_prediction'], label = 'FT-Transform prediction (with LeakeyRelu activation)', color = 'blue')\n",
        "plt.scatter(pred_df_tabnet['col1'], pred_df_tabnet['target_prediction'], label = 'TabNet prediction', color = 'green')\n",
        "plt.scatter(pred_df['col1'], pred_df['target'], label = 'True', color = 'black')\n",
        "plt.xlabel(\"X\", fontdict = font)\n",
        "plt.ylabel(\"Y = sin(0.1X) + 0.03X\", fontdict = font)\n",
        "plt.title(\"Homoskedastic and continuous dataset\", fontdict = font_title)\n",
        "plt.legend(fontsize = 14);"
      ],
      "metadata": {
        "id": "SuEgvvJpRx5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S9Vp-PJsRx-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node"
      ],
      "metadata": {
        "id": "nOhNdz-x2Wy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELS4GLsaoXhF"
      },
      "outputs": [],
      "source": [
        "# Node\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=num_col_names,\n",
        "    categorical_cols=cat_col_names,\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=None,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = NodeConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model_node = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model_node.fit(train=df_train, validation=df_valid)\n",
        "pred_df_node = tabular_model_node.predict(df_test, ret_logits=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,12))\n",
        "plt.scatter(pred_df['col1'], pred_df['target_prediction'], label = 'FT-Transform prediction (with ReLU activation)', color = 'purple')\n",
        "plt.scatter(pred_df_leakeyrelu['col1'], pred_df_leakeyrelu['target_prediction'], label = 'FT-Transform prediction (with LeakeyRelu activation)', color = 'blue')\n",
        "plt.scatter(pred_df_tabnet['col1'], pred_df_tabnet['target_prediction'], label = 'TabNet prediction', color = 'green')\n",
        "plt.scatter(pred_df_node['col1'], pred_df_node['target_prediction'], label = 'Node prediction', color = 'red')\n",
        "plt.scatter(pred_df['col1'], pred_df['target'], label = 'True', color = 'black')\n",
        "plt.xlabel(\"X\", fontdict = font)\n",
        "plt.ylabel(\"Y = sin(0.1X) + 0.03X\", fontdict = font)\n",
        "plt.title(\"Hohoskedastic and continuous dataset\", fontdict = font_title)\n",
        "plt.legend(fontsize = 14);"
      ],
      "metadata": {
        "id": "AgXjsX8R_MSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B9h78tKuB4ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7gvZsBOJB4cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PP5_wfZ_B4g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q6sm5luJB4jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GSeEqyHoB4nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4xylw1bwB4ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Y7kUAnNB4sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GMDOIPLpB4uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jawqwgu6B4wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R5S4QYyb0UUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabTransformer"
      ],
      "metadata": {
        "id": "EGukWF9I4M65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B10Y-fMGoXpL"
      },
      "outputs": [],
      "source": [
        "# TabTransformer\n",
        "\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=num_col_names,\n",
        "    categorical_cols=cat_col_names,\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=None,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = TabTransformerConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model_tabtransformer = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model_tabtransformer.fit(train=df_train, validation=df_valid)\n",
        "pred_df_tabtransformer = tabular_model_tabtransformer.predict(df_test, ret_logits=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,12))\n",
        "plt.scatter(pred_df['col1'], pred_df['target_prediction'], label = 'FT-Transform prediction (with ReLU activation)', color = 'purple')\n",
        "plt.scatter(pred_df_leakeyrelu['col1'], pred_df_leakeyrelu['target_prediction'], label = 'FT-Transform prediction (with LeakeyRelu activation)', color = 'blue')\n",
        "plt.scatter(pred_df_tabnet['col1'], pred_df_tabnet['target_prediction'], label = 'TabNet prediction', color = 'green')\n",
        "plt.scatter(pred_df_node['col1'], pred_df_node['target_prediction'], label = 'Node prediction', color = 'red')\n",
        "plt.scatter(pred_df_tabtransformer['col1'], pred_df_tabtransformer['target_prediction'], label = 'TabTransformer prediction', color = 'yellow')\n",
        "plt.scatter(pred_df['col1'], pred_df['target'], label = 'True', color = 'black')\n",
        "plt.xlabel(\"X\", fontdict = font)\n",
        "plt.ylabel(\"Y = sin(0.1X) + 0.03X\", fontdict = font)\n",
        "plt.title(\"Hohoskedastic and continuous dataset\", fontdict = font_title)\n",
        "plt.legend(fontsize = 14);"
      ],
      "metadata": {
        "id": "zs2Ed-M7_fRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoInt"
      ],
      "metadata": {
        "id": "Tt_CMZqG4Slk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NehzRQkoXvt"
      },
      "outputs": [],
      "source": [
        "# AutoInt\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 64\n",
        "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
        "data_config = DataConfig(\n",
        "    target=['target'],\n",
        "    continuous_cols=num_col_names,\n",
        "    categorical_cols=cat_col_names,\n",
        "#         continuous_feature_transform=\"quantile_uniform\"\n",
        ")\n",
        "trainer_config = TrainerConfig(\n",
        "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
        "    batch_size=batch_size,\n",
        "    max_epochs=epochs,\n",
        "    early_stopping_patience = 5,\n",
        "    gpus=None,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
        ")\n",
        "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
        "\n",
        "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
        "\n",
        "\n",
        "model_config = AutoIntConfig(\n",
        "    task = \"regression\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tabular_model_autoint = TabularModel(\n",
        "    data_config=data_config,\n",
        "    model_config=model_config,\n",
        "    optimizer_config=optimizer_config,\n",
        "    trainer_config=trainer_config\n",
        ")\n",
        "\n",
        "tabular_model_autoint.fit(train=df_train, validation=df_valid)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Vxp2Mc3-Un"
      },
      "outputs": [],
      "source": [
        "pred_df_autoint = tabular_model.predict(df_test, ret_logits=False)\n",
        "pred_df_autoint.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZigDn_f3-bb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,12))\n",
        "plt.scatter(pred_df['col1'], pred_df['target_prediction'], label = 'FT-Transform prediction (with ReLU activation)', color = 'purple')\n",
        "plt.scatter(pred_df_leakeyrelu['col1'], pred_df_leakeyrelu['target_prediction'], label = 'FT-Transform prediction (with LeakeyRelu activation)', color = 'blue')\n",
        "plt.scatter(pred_df_tabnet['col1'], pred_df_tabnet['target_prediction'], label = 'TabNet prediction', color = 'green')\n",
        "#plt.scatter(pred_df_node['col1'], pred_df_node['target_prediction'], label = 'Node prediction', color = 'red')\n",
        "plt.scatter(pred_df_tabtransformer['col1'], pred_df_tabtransformer['target_prediction'], label = 'TabTransformer prediction', color = 'yellow')\n",
        "plt.scatter(pred_df_autoint['col1'], pred_df_autoint['target_prediction'], label = 'AutoInt prediction', color = 'pink')\n",
        "plt.scatter(pred_df['col1'], pred_df['target'], label = 'True', color = 'black')\n",
        "plt.xlabel(\"X\", fontdict = font)\n",
        "plt.ylabel(\"Y = sin(0.1X) + 0.03X\", fontdict = font)\n",
        "plt.title(\"Hohoskedastic and continuous dataset\", fontdict = font_title)\n",
        "plt.legend(fontsize = 14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-gaG2vQ3-d2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amR7Rg5fYq84"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oNVHe_gYrBl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATxm5bn3YrDe"
      },
      "outputs": [],
      "source": [
        "def uncertainity_estimate(x, model, num_samples, l2):\n",
        "    outputs = np.hstack([model.predict(x, ret_logits=False).detach().numpy() for i in range(num_samples)]) # n번 inference, output.shape = [20, N]\n",
        "    y_mean = outputs.mean(axis=1)\n",
        "    y_variance = outputs.var(axis=1)\n",
        "    tau = l2 * (1. - model.dropout_rate) / (2. * N * model.decay)\n",
        "    y_variance += (1. / tau)\n",
        "    y_std = np.sqrt(y_variance)\n",
        "    return y_mean, y_std\n",
        "\n",
        "\n",
        "# Normalise data:\n",
        "\n",
        "x_mean, x_std = df_train['col1'].mean(), df_train['col1'].std()\n",
        "y_mean, y_std = df_train['target'].mean(), df_train['target'].std()\n",
        "x_obs = (df_train['col1'] - x_mean) / x_std\n",
        "y_obs = (df_train['target'] - y_mean) / y_std\n",
        "x_test = (df_valid['col1'] - x_mean) / x_std\n",
        "y_test = (df_valid['target'] - y_mean) / y_std\n",
        "\n",
        "iters_uncertainty = 200\n",
        "\n",
        "lengthscale = 0.01\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "n_std = 2 # number of standard deviations to plot\n",
        "y_mean, y_std = uncertainity_estimate(x = torch.Tensor(x_test).view(-1,1).to(device),\n",
        "                                      model = tabular_model, iters_uncertainty, lengthscale)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(x_obs, y_obs, ls=\"none\", marker=\"o\", color=\"0.1\", alpha=0.8, label=\"observed\")\n",
        "plt.plot(x_test, y_mean, ls=\"-\", color=\"b\", label=\"mean\")\n",
        "plt.plot(x_test, y_test, ls='--', color='r', label='true')\n",
        "for i in range(n_std):\n",
        "    plt.fill_between( x_test,\n",
        "        y_mean - y_std * ((i+1.)),\n",
        "        y_mean + y_std * ((i+1.)),\n",
        "        color=\"b\",\n",
        "        alpha=0.1)\n",
        "plt.legend()\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5uhqywhYrFg"
      },
      "outputs": [],
      "source": [
        "def uncertainity_estimate(x, model, num_samples, l2):\n",
        "    outputs = np.hstack([model(x).cpu().detach().numpy() for i in range(num_samples)]) # n번 inference, output.shape = [20, N]\n",
        "    y_mean = outputs.mean(axis=1)\n",
        "    y_variance = outputs.var(axis=1)\n",
        "    tau = l2 * (1. - model.dropout_rate) / (2. * N * model.decay)\n",
        "    y_variance += (1. / tau)\n",
        "    y_std = np.sqrt(y_variance)\n",
        "    return y_mean, y_std"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Research_full_work_cont_homosked.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}