{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2RX38Hg7sYf"
   },
   "outputs": [],
   "source": [
    "#! pip install pytorch_tabular[all]\n",
    "#! pip install pytorch_tabular\n",
    "# ! git clone https://github.com/manujosephv/pytorch_tabular\n",
    "# %cd pytorch_tabular\n",
    "# %pwd\n",
    "#!python setup.py install\n",
    "# !pip install setuptools==59.5.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFt3pYG9CBRZ"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skm4M3kNCDA1"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWebg7kxCESQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU38YNFNCFX7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt8KCSJHCH8v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4SYdQ0qCJ5l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLkTlOzNCK5w"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qmuotr7_UO0"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "if not IN_COLAB:\n",
    "    os.chdir(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, FTTransformerConfig, FTTransformerModel, TabNetModelConfig, TabNetModel, AutoIntConfig, AutoIntConfig, TabTransformerConfig, TabTransformerModel\n",
    "from pytorch_tabular.models import AutoIntModel, AutoIntConfig, NodeConfig, NODEModel\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig, ModelConfig\n",
    "from pytorch_tabular.models import BaseModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass, field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fshllPcm_Znv"
   },
   "outputs": [],
   "source": [
    "def make_mixed_regression(n_samples, n_features, n_categories):\n",
    "    X,y = make_regression(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5, n_targets=1)\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\n",
    "    for col in cat_cols:\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\n",
    "    col_names = [] \n",
    "    num_col_names=[]\n",
    "    cat_col_names=[]\n",
    "    for i in range(X.shape[-1]):\n",
    "        if i in cat_cols:\n",
    "            col_names.append(f\"cat_col_{i}\")\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\n",
    "        if i in num_cols:\n",
    "            col_names.append(f\"num_col_{i}\")\n",
    "            num_col_names.append(f\"num_col_{i}\")\n",
    "    X = pd.DataFrame(X, columns=col_names)\n",
    "    y = pd.DataFrame(y, columns=[\"target\"])\n",
    "    data = X.join(y)\n",
    "    return data, cat_col_names, num_col_names\n",
    "\n",
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim>1:\n",
    "        y_true=y_true.ravel()\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred=y_pred.ravel()\n",
    "    val_acc = mean_squared_error(y_true, y_pred)\n",
    "    val_f1 = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{tag} MSE: {val_acc} | {tag} MAE: {val_f1}\")\n",
    "\n",
    "data, cat_col_names, num_col_names = make_mixed_regression(n_samples=10000, n_features=4, n_categories=2)\n",
    "df_train, df_test = train_test_split(data, random_state=42)\n",
    "df_train, df_valid = train_test_split(data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IR36FyA8s6y"
   },
   "outputs": [],
   "source": [
    "# FT - Transformer\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols=['num_col_0', 'num_col_3'],\n",
    "    categorical_cols=['cat_col_1', 'cat_col_2'],\n",
    "#         continuous_feature_transform=\"quantile_uniform\"\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=epochs,\n",
    "    early_stopping_patience = 5,\n",
    "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
    "\n",
    "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
    "\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    task = \"regression\",\n",
    "    learning_rate=1e-3,\n",
    "    seed = 13,\n",
    "    input_embed_dim = 32,\n",
    "    num_heads = 8,\n",
    "    num_attn_blocks = 6,\n",
    "    ff_dropout = 0.1,\n",
    "    out_ff_layers = \"128-64-32\",\n",
    "    out_ff_activation = \"LeakyReLU\",\n",
    "    out_ff_initialization=\"kaiming\",\n",
    "    batch_norm_continuous_input=False,\n",
    "    #         target_range=[(df_train[col].min(),df_train[col].max()) for col in ['target']]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t75kvmAy-_10"
   },
   "outputs": [],
   "source": [
    "tabular_model.fit(train=df_train, validation=df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ImtR_xUJ2KM"
   },
   "outputs": [],
   "source": [
    "#prediction and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjbtykP_AQ03"
   },
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test, quantiles=[0.15,0.5,0.85], n_samples=1000, ret_logits=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG8jEEyRNUOI"
   },
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test, quantiles=[0.15,0.5,0.85], n_samples=1000, ret_logits=False)\n",
    "pred_df.head()\n",
    "\n",
    "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pNNU1iKNfbC"
   },
   "outputs": [],
   "source": [
    "plt.scatter(pred_df['num_col_0'], pred_df['target'], color = 'blue')\n",
    "plt.scatter(pred_df['num_col_0'], pred_df['target_prediction'], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdtgYVPONgk5"
   },
   "outputs": [],
   "source": [
    "plt.scatter(pred_df['num_col_3'], pred_df['target'], color = 'blue')\n",
    "plt.scatter(pred_df['num_col_3'], pred_df['target_prediction'], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWimhnBZORos"
   },
   "outputs": [],
   "source": [
    "plt.scatter(pred_df['cat_col_1'], pred_df['target'], color = 'blue')\n",
    "plt.scatter(pred_df['cat_col_1'], pred_df['target_prediction'], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnnY6dPJOSik"
   },
   "outputs": [],
   "source": [
    "plt.scatter(pred_df['cat_col_2'], pred_df['target'], color = 'blue')\n",
    "plt.scatter(pred_df['cat_col_2'], pred_df['target_prediction'], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKPFshoXKKQp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWquNQZyoXc4"
   },
   "outputs": [],
   "source": [
    "# TabNet\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols=['num_col_2', 'num_col_3'],\n",
    "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
    "#         continuous_feature_transform=\"quantile_uniform\"\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=epochs,\n",
    "    early_stopping_patience = 5,\n",
    "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
    "\n",
    "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
    "\n",
    "\n",
    "model_config = TabNetModelConfig(\n",
    "    task = \"regression\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=df_train, validation=df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1JesRev2pE0"
   },
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
    "pred_df.head()\n",
    "\n",
    "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELS4GLsaoXhF"
   },
   "outputs": [],
   "source": [
    "# Node\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols=['num_col_2', 'num_col_3'],\n",
    "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
    "#         continuous_feature_transform=\"quantile_uniform\"\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=epochs,\n",
    "    early_stopping_patience = 5,\n",
    "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
    "\n",
    "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
    "\n",
    "\n",
    "model_config = NodeConfig(\n",
    "    task = \"regression\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=df_train, validation=df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQQblmaFoXld"
   },
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
    "pred_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnbHb-WkoXnF"
   },
   "outputs": [],
   "source": [
    "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B10Y-fMGoXpL"
   },
   "outputs": [],
   "source": [
    "# TabTransformer\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols=['num_col_2', 'num_col_3'],\n",
    "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
    "#         continuous_feature_transform=\"quantile_uniform\"\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=epochs,\n",
    "    early_stopping_patience = 5,\n",
    "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
    "\n",
    "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
    "\n",
    "\n",
    "model_config = TabTransformerConfig(\n",
    "    task = \"regression\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=df_train, validation=df_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysOlamLKoXrQ"
   },
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
    "pred_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hmyBB-NoXtT"
   },
   "outputs": [],
   "source": [
    "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NehzRQkoXvt"
   },
   "outputs": [],
   "source": [
    "# AutoInt\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "steps_per_epoch = int((len(df_train)//batch_size)*0.9)\n",
    "data_config = DataConfig(\n",
    "    target=['target'],\n",
    "    continuous_cols=['num_col_2', 'num_col_3'],\n",
    "    categorical_cols=['cat_col_0', 'cat_col_1'],\n",
    "#         continuous_feature_transform=\"quantile_uniform\"\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=epochs,\n",
    "    early_stopping_patience = 5,\n",
    "    gpus=1,  #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "# optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
    "\n",
    "optimizer_config = OptimizerConfig(lr_scheduler=\"ReduceLROnPlateau\", lr_scheduler_params={\"patience\":3})\n",
    "\n",
    "\n",
    "model_config = AutoIntConfig(\n",
    "    task = \"regression\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=df_train, validation=df_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Vxp2Mc3-Un"
   },
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test, quantiles=[0.25,0.5,0.75], n_samples=100, ret_logits=False)\n",
    "pred_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mK6pM2CL3-W8"
   },
   "outputs": [],
   "source": [
    "print_metrics(pred_df['target'], pred_df[\"target_prediction\"], tag=\"Holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VmRC27B3-ZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZigDn_f3-bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-gaG2vQ3-d2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_Y_EHYw3-fj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwRefHkIoXyD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-iNv_AIYq6h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amR7Rg5fYq84"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oNVHe_gYrBl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATxm5bn3YrDe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5uhqywhYrFg"
   },
   "outputs": [],
   "source": [
    "def uncertainity_estimate(x, model, num_samples, l2):\n",
    "    outputs = np.hstack([model(x).cpu().detach().numpy() for i in range(num_samples)]) # n번 inference, output.shape = [20, N]\n",
    "    y_mean = outputs.mean(axis=1)\n",
    "    y_variance = outputs.var(axis=1)\n",
    "    tau = l2 * (1. - model.dropout_rate) / (2. * N * model.decay)\n",
    "    y_variance += (1. / tau)\n",
    "    y_std = np.sqrt(y_variance)\n",
    "    return y_mean, y_std"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FTTransformer_and_co.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
